{"meta":{"title":"Enmin`s blog","subtitle":null,"description":null,"author":"Enmin","url":"https://zem12345678.github.io"},"pages":[{"title":"about","date":"2018-10-16T08:50:22.000Z","updated":"2018-10-19T03:00:32.812Z","comments":true,"path":"about/index.html","permalink":"https://zem12345678.github.io/about/index.html","excerpt":"","text":"技术爱玩发与部署环境为 DockerPython 3.6.3前端 Vue + Webpack + ES2015 + axios后端 Django 2.0 + DjangoRestFramework + Celery自动化部署选用工具 Ansible 以及 Docker，K8s后端组件ElasticSearch 用于搜索和推荐PostgreSQL 用于数据持久化Mysql/Mangodb，用于数据存储Redis 缓存RabbitMQ 分布式队列 / 定时任务Nginx 用于反向代理如果你也是追新的 Django 开发者，一起来提 PR"}],"posts":[{"title":"Flask导出excel文件","slug":"Flask导出excel文件","date":"2019-03-14T01:50:50.660Z","updated":"2019-03-14T01:52:50.394Z","comments":true,"path":"2019/03/14/Flask导出excel文件/","link":"","permalink":"https://zem12345678.github.io/2019/03/14/Flask导出excel文件/","excerpt":"","text":"Flask导出excel文件 1response = make_response(output.getvalue()) 提示：flask中没有Httpreponse类型这一点与django不同我们需哟啊使用flask中make_responese来导入数据流]。 ##代码1234567891011121314151617181920212223242526272829303132333435now = datetime.now() time = datetime.strftime(now, &apos;%Y%m%d%H%M%S&apos;) 把时间格式化 filename = time + &apos;.xls&apos; # 创建一个sheet对象 wb = xlwt.Workbook(encoding=&apos;utf-8&apos;) sheet = wb.add_sheet(&apos;order-sheet&apos;) # 写入文件标题 sheet.write(0, 0, &apos;职工号&apos;) sheet.write(0, 1, &apos;姓名&apos;) sheet.write(0, 2, &apos;性别&apos;) sheet.write(0, 3, &apos;身份证号&apos;) sheet.write(0, 4, &apos;手机&apos;) sheet.write(0, 5, &apos;办公室&apos;) sheet.write(0, 6, &apos;邮箱&apos;) sheet.write(0, 7, &apos;QQ&apos;) data_row = 1 for teacher in Teacher.query.all(): sheet.write(data_row, 0, teacher.to_full_dict()[&apos;sno&apos;]) sheet.write(data_row, 1, teacher.to_full_dict()[&apos;name&apos;]) sheet.write(data_row, 2, teacher.to_full_dict()[&apos;sex&apos;]) sheet.write(data_row, 3, teacher.to_full_dict()[&apos;idcard_num&apos;]) sheet.write(data_row, 4, teacher.to_full_dict()[&apos;phone_num&apos;]) sheet.write(data_row, 5, teacher.to_full_dict()[&apos;office&apos;]) sheet.write(data_row, 6, teacher.to_full_dict()[&apos;email&apos;]) sheet.write(data_row, 7, teacher.to_full_dict()[&apos;qq&apos;]) data_row = data_row + 1 # 写出到IO output = BytesIO() wb.save(output) output.seek(0) response = make_response(output.getvalue()) response.headers[&apos;content_type=&apos;] = &apos; application/vnd.ms-excel&apos; # 创建一个文件对象 response.headers[&apos;Content-Disposition&apos;] = &apos;attachment;filename=&#123;&#125;&apos;.format(filename.encode().decode(&apos;latin-1&apos;)) return response","categories":[{"name":"Flask","slug":"Flask","permalink":"https://zem12345678.github.io/categories/Flask/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://zem12345678.github.io/tags/Python/"},{"name":"Web","slug":"Web","permalink":"https://zem12345678.github.io/tags/Web/"},{"name":"Flask","slug":"Flask","permalink":"https://zem12345678.github.io/tags/Flask/"}]},{"title":"django导入excel文件使用pandas处理并批量插入","slug":"django导入excel文件使用pandas处理并批量插入","date":"2019-03-14T01:26:04.463Z","updated":"2019-03-14T01:31:06.987Z","comments":true,"path":"2019/03/14/django导入excel文件使用pandas处理并批量插入/","link":"","permalink":"https://zem12345678.github.io/2019/03/14/django导入excel文件使用pandas处理并批量插入/","excerpt":"","text":"##导入库：123import pandas as pdimport xlwtfrom io import BytesIO #io数据流 ##django视图类1234567891011121314151617181920212223242526272829class ImportFarmerData(View): def post(self,request): excel_raw_data = pd.read_excel(request.FILES.get(&apos;file&apos;,&apos;&apos;),header=None) #删除第一行的标题 #获取每列 excel_raw_data.drop([0,0],inplace=True) name_col = excel_raw_data.iloc[:,[0]] card_id_col = excel_raw_data.iloc[:,[1]] phone_col = excel_raw_data.iloc[:,[2]] area_num_col = excel_raw_data.iloc[:,[3]]#对每一列数据进行处理，从DataFrame类型转换为list类型 name_list = name_col.values.tolist() card_id_list = card_id_col.values.tolist() phone_list = phone_col.values.tolist()#对每一列的每一行的数据进行转换，转换为str类型 for i in range(len(name_list)): name_list_index = name_list[i] card_id_list_index = card_id_list[i] phone_list_index = phone_list[i] area_num_index = area_num_list[i] farmer_profile = FarmersProfile() farmer_profile.name = name_list_index[0] farmer_profile.card_id = card_id_list_index[0] farmer_profile.phone = phone_list_index[0] farmer_profile.area_num = area_num_index[0] farmer_profile.address_id = address.id farmer_profile.save() return HttpResponse(json.dumps(&#123;&apos;code&apos;:&apos;200&apos;,&apos;msg&apos;:&apos;导入成功&apos;&#125;) 由于前端使用leiui返回格式必须为json格式 ##HTML：1&lt;button type=&quot;button&quot; class=&quot;layui-btn&quot; id=&quot;test4&quot; name=&quot;excel_data&quot;&gt;&lt;i class=&quot;layui-icon&quot;&gt;&lt;/i&gt;导入excel&lt;/button&gt; ##ajax:123456789101112131415161718192021layui.use(&apos;upload&apos;, function()&#123; var $ = layui.jquery, upload = layui.upload; //指定允许上传的文件类型 upload.render(&#123; //允许上传的文件后缀 elem: &apos;#test4&apos;, type: &apos;post&apos;, url: &apos;&#123;% url &apos;users:import_famer&apos; %&#125;&apos;, accept: &apos;file&apos;, //普通文件, exts: &apos;xls&apos;, //只允许上传压缩文件, data: &#123;&apos;csrfmiddlewaretoken&apos;: &apos;&#123;&#123; csrf_token &#125;&#125;&apos;&#125;, done: function(res) &#123; if (res.code == 200 ) &#123; layer.msg(res.msg); &#125; &#125; ,error:function (res) &#123; &#125; &#125;);","categories":[{"name":"django","slug":"django","permalink":"https://zem12345678.github.io/categories/django/"}],"tags":[{"name":"Django","slug":"Django","permalink":"https://zem12345678.github.io/tags/Django/"},{"name":"Python","slug":"Python","permalink":"https://zem12345678.github.io/tags/Python/"},{"name":"Web","slug":"Web","permalink":"https://zem12345678.github.io/tags/Web/"}]},{"title":"最长公共子序列（LCS）问题","slug":"最长公共子序列（LCS）问题","date":"2019-03-13T15:41:20.313Z","updated":"2019-03-13T15:43:40.156Z","comments":true,"path":"2019/03/13/最长公共子序列（LCS）问题/","link":"","permalink":"https://zem12345678.github.io/2019/03/13/最长公共子序列（LCS）问题/","excerpt":"","text":"#最长公共子序列（LCS）问题给定两个 1 到 n 的排列 A,B （即长度为 n 的序列，其中 [1,n] 之间的所有数都出现了恰好一次）。 求它们的最长公共子序列长度。 ##子序列： 一个序列A ＝ a1,a2,……an,中任意删除若干项，剩余的序列叫做A的一个子序列。也可以认为是从序列A按原顺序保留任意若干项得到的序列。 #求解算法对于母串X=&lt;x1,x2,⋯,xm&gt;, Y=&lt;y1,y2,⋯,yn&gt;，求LCS与最长公共子串。 ##暴力解法假设 m&lt;n， 对于母串X，我们可以暴力找出2的m次方个子序列，然后依次在母串Y中匹配，算法的时间复杂度会达到指数级O(n∗2的m次)。显然，暴力求解不太适用于此类问题。 ##动态规划假设Z=&lt;z1,z2,⋯,zk&gt;是X与Y的LCS， 我们观察到如果Xm=Yn，则Zk=Xm=Yn，有Zk−1是Xm−1与Yn−1的LCS；如果Xm≠Yn，则Zk是Xm与Yn−1的LCS，或者是Xm−1与Yn的LCS。因此，求解LCS的问题则变成递归求解的两个子问题。但是，上述的递归求解的办法中，重复的子问题多，效率低下。改进的办法——用空间换时间，用数组保存中间状态，方便后面的计算。先假设有 C[i,j] = | LCS(x[1…i] , y(1…j)) |，则有 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// n：表示两序列长度// a：描述序列 a（这里需要注意的是，由于 a 的下标从 1 开始，因此 a[0] 的值为-1，你可以忽略它的值，只需知道我们从下标 1 开始存放有效信息即可） // b：描述序列b（同样地，b[0] 的值为 -1）// 返回值：最长公共子序列的长度#include &lt;cstdio&gt; #include &lt;cstring&gt; #include &lt;cmath&gt; #include &lt;cstdlib&gt; #include &lt;algorithm&gt; #include &lt;queue&gt; #include &lt;stack&gt; #include &lt;map&gt; #include &lt;set&gt; #include &lt;vector&gt; #include &lt;iostream&gt;#include &lt;utility&gt;using namespace std;#define PII pair&lt;int,int&gt; #define PIII pair&lt;pair&lt;int,int&gt;,int&gt; #define mp make_pair#define pb push_back#define sz size() #define fi first#define se secondtypedef unsigned int ui;typedef long long ll;typedef unsigned long long ull;vector&lt;int&gt; pos,a,b,f;int getAns(int n,vector&lt;int&gt;a,vector&lt;int&gt;b)&#123; f.resize(n+1);pos.resize(n+1); for(int i=0;i&lt;=n;++i) f[i]=n+2; for(int i=1;i&lt;=n;++i)&#123; pos[b[i]]=i; &#125; for(int i=1;i&lt;=n;++i)&#123; a[i]=pos[a[i]]; &#125; f[0]=0; for(int i=1;i&lt;=n;++i) *lower_bound(f.begin(),f.end(),a[i])=a[i]; return int(lower_bound(f.begin(),f.end(),n+1)-f.begin())-1;&#125;int main()&#123; int n;scanf(&quot;%d&quot;,&amp;n); a.resize(n+1);b.resize(n+1); for(int i=1;i&lt;=n;++i)&#123; scanf(&quot;%d&quot;,&amp;a[i]); &#125; for(int i=1;i&lt;=n;++i)&#123; scanf(&quot;%d&quot;,&amp;b[i]); &#125; printf(&quot;%d\\n&quot;,getAns(n,a,b)); return 0;&#125; #输出结果123451 2 4 3 55 2 3 4 12","categories":[{"name":"算法","slug":"算法","permalink":"https://zem12345678.github.io/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://zem12345678.github.io/tags/算法/"},{"name":"C/C++","slug":"C-C","permalink":"https://zem12345678.github.io/tags/C-C/"},{"name":"Leetcood","slug":"Leetcood","permalink":"https://zem12345678.github.io/tags/Leetcood/"},{"name":"数据结构","slug":"数据结构","permalink":"https://zem12345678.github.io/tags/数据结构/"}]},{"title":"Django Restful Framework(DRF)的开发思考（2）","slug":"Django Restful Framework(DRF)的开发思考（2）","date":"2019-03-13T14:59:11.338Z","updated":"2019-03-13T15:24:48.092Z","comments":true,"path":"2019/03/13/Django Restful Framework(DRF)的开发思考（2）/","link":"","permalink":"https://zem12345678.github.io/2019/03/13/Django Restful Framework(DRF)的开发思考（2）/","excerpt":"","text":"Restful一种软件架构风格、设计风格，而不是标准，只是提供了一组设计原则和约束条件。它主要用于客户端和服务器交互类的软件。基于这个风格设计的软件可以更简洁，更有层次，更易于实现缓存等机制： CORS CORS是现代浏览亲支持快于请求的一种方式，全称是“跨域资源共享“(Cross-origin resource sharing),当使用XMLHttpRequest发送请求时，浏览器发现该请求不符合同源测率，会给该请求头：Origin，后台进行以系列处理，如果确定请求则在返回结果加入一个响应头：Access-Control-Allow-Origin；浏览器判断该响应头中是否包含Origin的值，如果有浏览器会处理响应，我们就可以拿到响应数据，如果不包含浏览器之间驳回，这时我们无法拿到响应数据 JWT ：Json web token (JWT), 是为了在网络应用环境间传递声明而执行的一种基于JSON的开放标准（(RFC 7519).该token被设计为紧凑且安全的，特别适用于分布式站点的单点登录（SSO）场景。JWT的声明一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源，也可以增加一些额外的其它业务逻辑所必须的声明信息，该token也可直接被用于认证，也可被加密；FastDFS ：FastDFS 是用 c 语言编写的一款开源的分布式文件系统。FastDFS 为互联网量身定制， 充分考虑了冗余备份、负载均衡、线性扩容等机制，并注重高可用、高性能等指标，使用 FastDFS 很容易搭建一套高性能的文件服务器集群提供文件上传、下载等服务。FastDFS 架构包括 Tracker server 和 Storage server。客户端请求 Tracker server 进行文 件上传、下载，通过 Tracker server 调度最终由 Storage server 完成文件上传和下载。 [TOC] Django认证系统|跨域请求|Celery提供了用户模型类User和User的相关操作方法。 自定义User模型类之后，需要设置配置项AUTH_USER_MODEL。 1. 前后端域名设置域名和IP是对应的关系。 DNS解析：获取域名对应的IP 通过域名访问网站时，先到本地的hosts中查找IP和域名的对应关系，如果查到直接根据IP访问网站，如果查不到再进行DNS域名解析。 前端服务器域名: www.meiduo.site 后端API服务器域名：api.meiduo.site 2. 短信验证码123456URL: GET /sms_codes/(?P&lt;mobile&gt;1[3-9]\\d&#123;9&#125;)/参数: url地址中传递mobile响应: &#123; \"message\": \"OK\" &#125; ###3. 跨域请求 浏览器的同源策略: 协议、主机IP和端口PORT相同的地址是同源，否则是非同源。 当发起请求的页面地址和被请求的地址不是同源，那么这个请求就是跨域请求。 在发起请求时，如果浏览器发现请求是跨域请求，那么在请求的报文头中，会添加如下信息: Origin: 源请求IP地址 例如：Origin: http://www.meiduo.site:8080 在被请求的服务器返回的响应中，如果响应头中包含如下信息： Access-Control-Allow-Origin: 源请求IP地址 例如：Access-Control-Allow-Origin: http://www.meiduo.site:8080 那么浏览器认为被请求服务器支持来源地址对其进行跨域请求，否则认为不支持，浏览器会将请求直接驳回。 Django跨域请求扩展使用。 4. celery异步任务队列本质: ​ 使用进程或协程调用函数实现异步。 基本概念： ​ 发出者：发出所有执行的任务(任务就是函数)。 ​ (中间人)任务队列：存放所要执行的任务信息。 ​ 处理者：也就是工作的进程或协程，负责监听任务队列，发现任务便执行对应的任务函数。 特点： ​ 1）任务发送者和处理者可以分布在不同的电脑上，通过中间人进行信息交换。 ​ 2）任务队列中的任务会进行排序，先添加的任务会被先执行。 使用： ​ 1）安装 pip install celery ​ 2）创建Celery对象并配置中间人地址 ​ from celery import Celery ​ celery_app = Celery(‘demo’) ​ 配置文件：broker_url=’中间人地址’ ​ celery_app.config_from_object(‘配置文件路径’) ​ 3）定义任务函数 ​ @celery_app.task(name=’my_first_task’) ​ def my_task(a, b): ​ print(‘任务函数被执行’) ​ … ​ 4）启动worker ​ celery -A ‘celery_app文件路径’ worker -l info ​ 5）发出任务 ​ my_task.delay(2, 3) 5. 用户注册12345678910111213141516URL: POST /users/参数: &#123; \"username\": \"用户名\", \"password\": \"密码\", \"password2\": \"重复密码\", \"mobile\": \"手机号\", \"sms_code\": \"短信验证码\", \"allow\": \"是否同意协议\" &#125;响应: &#123; \"id\": \"用户id\", \"username\": \"用户名\", \"mobile\": \"手机号\" &#125; ###补充(axios请求发送) 1234567891011121314151617axios.get('url地址', [config]) .then(response =&gt; &#123; // 请求成功，可通过response.data获取响应数据 &#125;) .catch(error =&gt; &#123; // 请求失败，可通过error.response获取响应对象 // error.response.data获取响应数据 &#125;)axios.post('url地址', [data], [config]) .then(response =&gt; &#123; // 请求成功，可通过response.data获取响应数据 &#125;) .catch(error =&gt; &#123; // 请求失败，可通过error.response获取响应对象 // error.response.data获取响应数据 &#125;) 注册|JWT Token|普通登录1. 用户注册12345678910111213141516URL: POST /users/参数: &#123; \"username\": \"用户名\", \"password\": \"密码\", \"password2\": \"重复密码\", \"mobile\": \"手机号\", \"sms_code\": \"短信验证码\", \"allow\": \"是否同意协议\" &#125;响应: &#123; \"id\": \"用户id\", \"username\": \"用户名\", \"mobile\": \"手机号\" &#125; 创建新用户：User.objects.create_user(username, email=None, password=None, *\\extra_fields*) 2. JWT token1）session认证 12345671. 接收用户名和密码2. 判断用户名和密码是否正确3. 保存用户的登录状态(session) session['user_id'] = 1 session['username'] = 'smart' session['mobile'] = '13155667788'4. 返回应答，登录成功 session认证的一些问题: session存储在服务器端，如果登录的用户过多，服务器开销比较大。 session依赖于cookie，session的标识存在cookie中，可能会有CSRF(跨站请求伪造)。 2）jwt 认证机制(替代session认证) 12341. 接收用户名和密码2. 判断用户名和密码是否正确3. 生成(签发)一个jwt token(token中保存用户的身份信息) 公安局(服务器)=&gt;签发身份证(jwt token)4. 返回应答，将jwt token信息返回给客户端。 如果之后需要进行身份认证，客户端需要将jwt token发送给服务器，由服务器验证jwt token的有效性。 3）jwt 的数据格式 12eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFO a）headers头部 1234&#123; &quot;token类型声明&quot;, &quot;加密算法&quot;&#125; base64加密(很容易被解密) b）payload(载荷)：用来保存有效信息 123456&#123; &quot;user_id&quot;: 1, &quot;username&quot;: &quot;smart&quot;, &quot;mobile&quot;: &quot;13155667788&quot;, &quot;exp&quot;: &quot;有效时间&quot;&#125; base64加密 c）signature(签名)：防止jwt token被伪造 将headers和payload进行拼接，用.隔开，使用一个密钥(secret key)进行加密，加密之后的内容就是签名。 jwt token是由服务器生成，密钥保存在服务器端。 3. jwt 扩展签发jwt token1234567from rest_framework_jwt.settings import api_settingsjwt_payload_handler = api_settings.JWT_PAYLOAD_HANDLERjwt_encode_handler = api_settings.JWT_ENCODE_HANDLERpayload = jwt_payload_handler(user)token = jwt_encode_handler(payload) 4. 用户登录1）jwt 扩展的登录视图obtain_jwt_token： ​ 接收username和password，进行用户名和密码验证，正确情况下签发jwt token并返回给客户端。 2）更改obtain_jwt_token组织响应数据的函数： 123456789101112131415def jwt_response_payload_handler(token, user=None, request=None): \"\"\" 自定义jwt认证成功返回数据 \"\"\" return &#123; 'token': token, 'user_id': user.id, 'username': user.username &#125;# JWT扩展配置JWT_AUTH = &#123; # ... 'JWT_RESPONSE_PAYLOAD_HANDLER': 'users.utils.jwt_response_payload_handler',&#125; 3）登录支持用户名和手机号 123obtain_jwt_token-&gt; from django.contrib.auth import authenticate-&gt; from django.contrib.auth.backends import ModelBackend(authenticate: 根据用户名和密码进行校验) 自定义Django的认证系统后端，同时设置配置项AUTHENTICATION_BACKENDS。 ##QQ登录 1. QQ登录-预备工作1）成为QQ开发者 2）创建开发者应用 3）查询QQ登录开发文档 2. QQ登录-开发关键点获取QQ登录用户的唯一身份标识(openid)，然后根据openid进行处理。 判断该QQ用户是否绑定过本网站的用户，如果绑定过，直接登录，如果未绑定过，先进行绑定。 QQ用户绑定: 将openid 和 用户user_id 对应关系存下来。 id user_id openid 1 2 Akdk19389kDkdkk99939kdk 2 2 AKdkk838e8jdiafkdkkFKKKFf 注：一个用户可以绑定多个qq账户。 3. QQ登录API1）获取QQ登录网址API 12345API: GET /oauth/qq/authorization/?next=&lt;url&gt;响应:&#123; \"login_url\": \"QQ登录网址\"&#125; 2）获取QQ登录用户openid并进行处理API 12345678910111213API: GET /oauth/qq/user/?code=&lt;code&gt;参数: code响应: 1）如果openid已经绑定过本网站的用户，直接签发jwt token，返回 &#123; 'user_id': &lt;用户id&gt;, 'username': &lt;用户名&gt;, 'token': &lt;token&gt; &#125; 2）如果openid没有绑定过本网站的用户，先对openid进行加密生成token，把加密的内容返回 &#123; 'access_token': &lt;token&gt; &#125; 3）绑定QQ登录用户的信息API 1234567891011121314API: POST /oauth/qq/user/参数: &#123; \"mobile\": &lt;手机号&gt;, \"password\": &lt;密码&gt;, \"sms_code\": &lt;短信验证码&gt;, \"access_token\": &lt;access_token&gt; &#125;响应: &#123; 'id': &lt;用户id&gt;, 'username': &lt;用户名&gt;, 'token': &lt;token&gt; &#125; ###4. 相关模块的使用 1234567891011# 将python字典转化为查询字符串from urllib.parse import urlencode # 将查询字符串转换成python字典from urllib.parse import parse_qs# 发起网络请求from urllib.request import urlopen# itsdangerous: 加密和解密from itsdangerous import TimedJSONWebSignatureSerializer ##邮件发送|省市三级联动 个人信息获取1）给User添加email_active字段，用于记录邮箱email是否被激活。 2）API接口：获取用户个人信息。 123456789101112请求方式和URL地址: GET /user/前端传递参数: 在请求头中携带jwt token。返回值: &#123; \"id\": \"&lt;用户id&gt;\", \"username\": \"&lt;用户名&gt;\", \"mobile\": \"&lt;手机号&gt;\", \"email\": \"&lt;邮箱&gt;\", \"email_active\": \"&lt;激活标记&gt;\" &#125;注: DRF中`JSONWebTokenAuthentication`认证机制会根据jwt token对用户身份进行认证，如果认证失败返回401错误，如果是权限禁止返回403错误。 3）使用RetrieveAPIView时，其获取单个对象时是根据pk获取，我们这里所有获取的是当前登录的用户，所以需要把get_object方法进行重写。 4）request对象的user属性。 对于request对象，有一个user属性。这个user属性： ​ a）如果用户认证成功，request.user是User模型类的实例对象，存放的是当前登录用户的信息。 ​ b）如果用户未认证，request.user是AnonymousUser类的实例对象。 ###用户邮箱设置 1）API接口：设置用户个人邮箱。 123456789请求方式和URL地址: PUT /email/前端传递参数: 1）在请求头中携带jwt token。 2）邮箱email返回值: &#123; \"id\": \"&lt;用户id&gt;\", \"email\": \"&lt;邮箱&gt;\", &#125; 2）处理流程: ​ a）接收参数并进行校验(email是否传递，格式是否正确) ​ b）保存用户的邮箱信息并发送激活邮件 ​ c）返回应答，设置邮箱成功 3）发送激活邮件 ​ a）生成激活链接：在激活链接中需要保存待激活用户的id和email，但是为了安全，需要对信息进行加密。 ​ b）发送邮件：配置文件中先进行邮件发送配置，在使用django的send_mail方法发送邮件，为了不影响邮件设置过程，邮件采用celery发送。 12from django.core.mail import send_mailsend_mail(subject='邮件主题', message='正文', from_email='发件人', recipient_list='收件人列表', html_message='html邮件正文') 个人邮箱激活1）API接口：激活用户个人邮箱。 1234567请求方式和URL地址: GET /emails/verification/?token=xxx前端传递参数: 1）token返回值: &#123; \"message\": \"处理结果\" &#125; 2）处理流程: ​ a）接收参数token并进行校验(token是否传递，token是否有效) ​ b）将用户邮箱激活标记设置为已激活。 ​ c）返回应答，邮箱激活成功。 省市县三级信息1）信息存储(自关联) 地区的自关联其实是一个特殊一对多的关系。 一个省包含很多个市，一个市包含很多县。 id(地区id) name(地区名) parent_id(父级地区ID) 320000 江苏省 NULL 320200 无锡市 320000 320282 宜兴市 320200 2）模型类自关联(地区的自关联其实是一个特殊的一对多) 123456class Area(models.Model): \"\"\" 行政区域 \"\"\" name = models.CharField(max_length=20, verbose_name='名称') parent = models.ForeignKey('self', on_delete=models.SET_NULL, related_name='subs', null=True, blank=True, verbose_name='上级行政区域') 注：模型类自关联，ForeignKey第一个参数传self。 另外之前的关联查询中，有了一个area对象之后，查询关联的下级地区信息和父级地区，例如: 123area = Area.objects.get(id='320200')area.parent # 父级地区，由多查一，对象名.关联属性area.area_set.all() # 子级地区，由一查多，对象名.多类名_set.all() 当ForeignKey创建关联属性时，指定了related_name=&#39;subs&#39;之后，再查询和area对象关联的子级地区，不在使用area.area_set.all()，而是使用area.subs.all()。 3）定义导入地区信息shell脚本 12#! /bin/bashmysql -u'&lt;用户名&gt;' -p'&lt;密码&gt;' -h'&lt;数据库主机IP&gt;' '&lt;数据库名&gt;' &lt; '&lt;sql文件&gt;' 4）地区视图集。 ###补充(客户端发送请求时携带JWT token数据) 12345678910111213axios.get(this.host + '/user/', &#123; headers: &#123; // 通过请求头向后端传递JWT token的方法 'Authorization': 'JWT ' + &lt;JWT token数据&gt; &#125;, responseType: 'json',&#125;).then(response =&gt; &#123; ...&#125;).catch(error =&gt; &#123; ...&#125;);","categories":[{"name":"前后端分离","slug":"前后端分离","permalink":"https://zem12345678.github.io/categories/前后端分离/"}],"tags":[{"name":"Django","slug":"Django","permalink":"https://zem12345678.github.io/tags/Django/"},{"name":"Restful","slug":"Restful","permalink":"https://zem12345678.github.io/tags/Restful/"},{"name":"前后端分离","slug":"前后端分离","permalink":"https://zem12345678.github.io/tags/前后端分离/"}]},{"title":"Django Restful Framework(DRF)的开发思考（1）","slug":"Django Restful Framework(DRF)的开发思考（1）","date":"2019-03-13T14:19:12.518Z","updated":"2019-03-13T15:15:18.691Z","comments":true,"path":"2019/03/13/Django Restful Framework(DRF)的开发思考（1）/","link":"","permalink":"https://zem12345678.github.io/2019/03/13/Django Restful Framework(DRF)的开发思考（1）/","excerpt":"","text":"Restful一种软件架构风格、设计风格，而不是标准，只是提供了一组设计原则和约束条件。它主要用于客户端和服务器交互类的软件。基于这个风格设计的软件可以更简洁，更有层次，更易于实现缓存等机制： CORS CORS是现代浏览亲支持快于请求的一种方式，全称是“跨域资源共享“(Cross-origin resource sharing),当使用XMLHttpRequest发送请求时，浏览器发现该请求不符合同源测率，会给该请求头：Origin，后台进行以系列处理，如果确定请求则在返回结果加入一个响应头：Access-Control-Allow-Origin；浏览器判断该响应头中是否包含Origin的值，如果有浏览器会处理响应，我们就可以拿到响应数据，如果不包含浏览器之间驳回，这时我们无法拿到响应数据 JWT ：Json web token (JWT), 是为了在网络应用环境间传递声明而执行的一种基于JSON的开放标准（(RFC 7519).该token被设计为紧凑且安全的，特别适用于分布式站点的单点登录（SSO）场景。JWT的声明一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源，也可以增加一些额外的其它业务逻辑所必须的声明信息，该token也可直接被用于认证，也可被加密； FastDFS ：FastDFS 是用 c 语言编写的一款开源的分布式文件系统。FastDFS 为互联网量身定制， 充分考虑了冗余备份、负载均衡、线性扩容等机制，并注重高可用、高性能等指标，使用 FastDFS 很容易搭建一套高性能的文件服务器集群提供文件上传、下载等服务。FastDFS 架构包括 Tracker server 和 Storage server。客户端请求 Tracker server 进行文 件上传、下载，通过 Tracker server 调度最终由 Storage server 完成文件上传和下载。 ##Web网站中开发模式（前后端分离&amp;前后端不分离） web开发模式 开发模式 说明 前后端不分离 前端展示的数据效果最终是由后端进行控制的，由后端使用模板进行模板的渲染，将渲染后的内容返回给客户端进行显示 前后端分离 后端服务器只返回前端所需要数据，前端获取数据之后自己控制数据怎么进行展示 注意：前端发起ajax-&gt;后端服务器返回分类新闻数据-&gt;前端进行页面拼接和展示。 RestAPI接口风格前后端分离开发中广泛采用的一种API设计风格。​关键点：url地址尽量使用名词，不要出现动词。采用不同请求方式，执行不同操作。 GET 获取​POST 新增PUT 修改​DELETE 删除GET /books/: 获取所有图书，返回所有图书信息POST /books/: 新建一本图书，返回新建的图书信息GET /books/id/: 获取指定图书，返回指定图书信息PUT /books/id/: 修改指定图书，返回修改图书信息DELETE /books/id/: 删除指定图书，返回空文档 过滤参数放在查询字符串中。响应状态码选择。 200：获取或修改​201：新建​204：删除​400：客户端请求有误​404：客户端请求的资源找不到​500：服务器出错 响应数据返回json。 ###使用Django知识自定义RestAPI接口准备工作-&gt;创建应用-&gt;定义模板类-&gt;生成数据表-&gt;添加测试数据。 使用Django知识自定义RestAPI接口: 获取所有图书的信息 GET /books/ 新增一本图书信息 POST /books/ 获取指定的图书信息 GET /books/(?P\\d+)/ 修改指定的图书信息 PUT /books/(?P\\d+)/ 删除指定的图书信息 DELETE /books/(?P\\d+)/ ###RestAPI接口开发时的工作(序列化和反序列化) 开发模式 说明 序列化 将程序中一种数据结构类型转化为其他的数据格式，这个过程叫做序列化。在我们前面例子中，将模型对象转化为python字典或json数据，这个过程可以认为是序列化过程。 反序列化: 将其他格式数据转换为程序中数据，这个过程叫做反序列化。在我们前面例子中，将客户端发送的数据保存在模型对象中，这个过程可以认为是反序列化过程。 主要工作 ​ 1）将请求数据保存在模型对象中(反序列化)。​ 2）操作数据库。​ 3）将模型对象转换为前端所需的格式(序列化)。 ## ##序列化器|视图类|拓展类 ###序列化类的功能：进行序列化和反序列化 序列化：将对象转化为字典数据反序列化：1）数据校验 2）数据保存(新增&amp;更新)。定义序列化器类：继承Serializer或ModelSerializer 1234567891011121314151617181920212223242526272829from rest_framework import serializers# serializers.Serializer：定义任何序列化器类时，都可以直接继承于Serializer# serializers.ModelSerializer：如果定义的序列化器类针对的是一个模型类，可以直接继承ModelSerializerclass User(object): def __init__(self, username, age): self.username = username self.age = ageclass UserSerializer(serializers.Serializer): &quot;&quot;&quot;序列化器类&quot;&quot;&quot; # 序列化器字段 = serializers.字段类型(选项参数) username = serializers.CharField() age = serializers.IntegerField()if __name__ == &apos;__main__&apos;: user = User(&apos;smart&apos;, 18) # &#123; # &quot;username&quot;: &quot;smart&quot;, # &quot;age&quot;: 18 # &#125; serializer = UserSerializer(user) # 获取序列化之后的字典数据 serializer.data &quot;hello&quot; 1. 序列化器-序列化1）序列化单个对象 123book = BookInfo.objects.get(id=1)serializer = BookInfoSerializer(book)serializer.data 2）序列化多个对象 123books = BookInfo.objects.all()serializer = BookInfoSerializer(books, many=True)serializer.data 3）关联对象的序列化 123451. 将关联对象序列化为关联对象主键 PrimaryKeyRelatedFieldå2. 将关联对象使用指定的序列化器进行序列化3. 将关联对象序列化为关联对象模型类__str__方法的返回值 StringRelatedField注意：如果关联对象有多个，定义字段时，需要添加many=True ###2. 序列化器-反序列化 1）反序列化之数据校验 1234567891011data = &#123;'btitle': 'python'&#125;serializer = BookInfoSerializer(data=data)serializer.is_valid() # 调用此方法会对传递的data数据内容进行校验，校验成功返回True, 否则返回Falseserializer.errors # 获取校验失败的错误信息serializer.validated_data # 获取校验之后的数据# 补充验证行为1. 对对应的字段指定validators2. 序列化器类中定义对应的方法validate_&lt;field_name&gt;对指定的字段进行校验3. 如果校验需要结合多个字段内容，定义validate方法 2）反序列化之数据保存(新增或更新) 1234567891011121314151617# 数据校验之后，调用此方法可以进行数据保存，可能会调用序列化器类中的create或updateserializer.save() # 调用create，创建序列化器对象时只传递了datadata = &#123;'btitle': 'python'&#125;serializer = BookInfoSerializer(data=data)serializer.is_valid()serializer.save()# 调用update，创建序列化器对象时传递了data和对象book = BookInfo.objects.get(id=1)data = &#123;'btitle': 'python'&#125;serializer = BookInfoSerializer(book, data=data)serializer.is_valid()serializer.save()# 注意: Serializer类中create和update没有进行实现，需要自己实现代码。 3. 使用Serializer改写Django自定义RestAPI接口将序列化和反序列化部分代码使用序列化器完成。 4. APIView视图类&amp;Request对象&amp;Response对象1）APIView视图类 ​ APIView是DRF框架中所有视图类的父类。 ​ 继承自APIView之后，处理函数中的request参数不再是Django原始的HttpRequest对象，而是由DRF框架封装的Request类的对象。 ​ 进行异常处理。 ​ 认证&amp;权限&amp;限流。 2）Request类| 属性 | 说明 || :——– | ——–:|| equest.data: | 包含传递的请求体数据(比如之前的request.body和request.POST)，并且已经转换成了字典或类字典类型。 || 前后端分离 | 包含查询字符串参数(相当于之前的request.GET) |​3）Response类 ​ 通过Response返回响应数据时，会根据前端请求头中的Accept转化成对应的响应数据类型，仅支持json和html，默认返回json。 4）补充 类视图对象`self.kwargs`保存这从url地址中提取的所有命名参数。 5. 使用APIView改写Django自定义RestAPI接口将获取参数以及响应部分代码进行改写。 6. GenericAPIView视图类APIView类的子类，封装了操作序列化器和操作数据库的方法，经常和Mixin扩展类配合使用。 过滤&amp;分页。 属性： ​serializer_class: 指定视图使用的序列化器类​queryset: 指定视图使用的查询集 方法: get_serializer_class: 返回当前视图使用的序列化器类​get_serializer: 创建一个序列化器类的对象​get_queryset: 获取当前视图使用的查询集​get_object: 获取单个对象，默认根据主键进行查询 ##子类视图类|视图集|路由Router| 类名 | 说明 || ————– | ———————————————————— || APIView | 1）继承自View，封装了Django 本身的HttpRequest对象为Request对象。2）统一的异常处理。 3）认证&amp;权限&amp;限流。 || GenericAPIView | 1）继承自APIView，提供了操作序列化器和数据库数据的方法，通常和Mixin扩展类配合使用。2）过滤&amp;分页。 | ###1. Mixin扩展类 DRF提供了5个扩展类，封装了5个通用的操作流程。 类名 说明 ListModelMixin 提供了一个list方法，封装了返回模型数据列表信息的通用流程。 CreateModelMixin 提供了一个create方法，封装了创建一个模型对象数据信息的通用流程。 RetrieveModelMixin 提供了一个retrieve方法，封装了获取一个模型对象数据信息的通用流程。 UpdateModelMixin 提供了一个update方法，封装了更新一个模型对象数据信息的通用流程。 DestroyModelMixin 提供了一个destroy方法，封装了删除一个模型对象数据信息的通用流程。 ###2. 子类视图 为了方便我们开发RestAPI，DRF框架除了提供APIView和GenericAPIView视图类之外，还提供了一些子类视图类，这些子类视图类同时继承了GenericAPIView和对应的Mixin扩展类，并且提供了对应的请求方法。 类名 说明 ListAPIView 1）继承自ListModelMixin和GenericAPIView。2）如果想定义一个视图只提供列出模型列表信息的接口，继承此视图类是最快的方式。 CreateAPIView 1）继承自CreateModelMixin和GenericAPIView。2）如果想定义一个视图只提供创建一个模型信息的接口，继承此视图类是最快的方式。 RetrieveAPIView 1）继承自RetrieveModelMixin和GenericAPIView。2）如果想定义一个视图只提供获取一个模型信息的接口，继承此视图类是最快的方式。 UpdateAPIView 1）继承自UpdateModelMixin和GenericAPIView。2）如果只想定义一个视图只提供更新一个模型信息的接口，继承此视图类是最快的方式。 DestroyAPIView 1）继承自DestroyModelMixin和GenericAPIView。2）如果只想定义一个视图只提供删除一个模型信息的接口，继承此视图类是最快的方式。 ListCreateAPIView 1）继承自ListModelMixin，CreateModelMixin和GenericAPIView。2）如果只想定义一个视图提供列出模型列表和创建一个模型信息的接口，继承此视图类是最快的方式。 RetrieveUpdateAPIView 1）继承自RetrieveModelMixin，UpdateModelMixin和GenericAPIView。2）如果只想定义一个视图提供获取一个模型信息和更新一个模型信息的接口，继承此视图类是最快的方式。 RetrieveDestroyAPIView 1）继承自RetrieveModelMixin，DestroyModelMixin和GenericAPIView。2）如果只想定义一个视图提供获取一个模型信息和删除一个模型信息的接口，继承此视图类是最快的方式。 RetrieveUpdateDestoryAPIView 1）继承自RetrieveModelMixin，UpdateModelMixin，DestroyModelMixin和GenericAPIView。2）如果只想定义一个视图提供获取一个模型信息和更新一个模型信息和删除一个模型信息的接口，继承此视图类是最快的方式。 示例1： 123456789101112131415161718# 需求1：写一个视图，提供一个接口 1. 获取一组图书数据 GET /books/ class BookListView(ListAPIView): queryset = BookInfo.objects.all() serializer_class = BookInfoSerializer # 需求2：写一个视图，提供一个接口 1. 获取指定的图书数据 GET /books/(?P&lt;pk&gt;\\d+)/ class BookDetailView(RetrieveAPIView): queryset = BookInfo.objects.all() serializer_class = BookInfoSerializer # 需求3：写一个视图，提供两个接口 1. 获取指定的图书数据 GET /books/(?P&lt;pk&gt;\\d+)/ 2. 更新指定的图书数据 PUT /books/(?P&lt;pk&gt;\\d+)/ class BookDetailView(RetrieveUpdateAPIView): queryset = BookInfo.objects.all() serializer_class = BookInfoSerializer ###3. 视图集类 将操作同一资源的处理方法放在同一个类中(视图集)，处理方法不要以请求方式命名，而是以对应的action命名， ​ list: 提供一组数据 ​ create: 创建一条新数据 ​ retrieve: 获取指定的数据 ​ update: 更新指定的数据 ​ destroy: 删除指定的数据 进行url配置时需要指明请求方法和处理函数之间的对应关系。 类名 说明 ViewSet 1）继承自ViewSetMixin和APIView。2）如果使用视图集时不涉及数据库和序列化器的操作，可以直接继承此类。 GenericViewSet 1）继承自ViewSetMixin和GenericAPIView。2）如果使用视图集涉及数据库和序列化器的操作，可以直接继承此类。 ModelViewSet 1）继承自5个Mixin扩展类和GenericViewSet。2）如果使用视图集想一次提供通用的5种操作，继承这个类是最快的。 ReadOnlyModelViewSet 1）继承自ListModelMixin，RetrieveModelMixin和GenericViewSet。2）如果使用视图集想一次提供list操作和retrieve操作，继承这个类是最快的。 示例1： 123456789101112131415161718192021# 需求1：写一个视图集，提供以下两种操作 1. 获取一组图书信息(list) GET /books/ 2. 新建一本图书信息(create) POST /books/ class BookInfoViewSet(ListModelMixin, CreateModelMixin, GenericViewSet): queryset = BookInfo.objects.all() serializer_class = BookInfoSerializer# 需求2：写一个视图集，提供以下两种操作 1. 获取一组图书信息(list) GET /books/ 2. 获取指定图书信息(retrieve) GET /books/(?P&lt;pk&gt;\\d+)/ class BookInfoViewSet(ReadOnlyModelViewSet): queryset = BookInfo.objects.all() serializer_class = BookInfoSerializer # 需求3：写一个视图集，提供以下三种操作 1. 获取一组图书信息(list) GET /books/ 2. 获取指定图书信息(retrieve) GET /books/(?P&lt;pk&gt;\\d+)/ 3. 更新指定图书信息(update) PUT /books/(?P&lt;pk&gt;\\d+)/ class BookInfoViewSet(UpdateModelMixin, ReadOnlyModelViewSet): queryset = BookInfo.objects.all() serializer_class = BookInfoSerializer 注: 除了常见的5种基本操作之外，如果想给一个视图集中添加其他处理方法，直接在视图集中定义即可。 ###4. 路由Router 1）路由Router是专门配合视图集来使用的，可以使用Router自动生成视图集中相应处理函数对应的URL配置项。 2）使用Router自动生成视图集中相应处理函数对应的URL配置项时，除了常见的5种基本操作之外，如果视图集中有添加的其他处理方法，则需要给这些方法加上action装饰器之后，才会动态生成其对应的URL配置项。 ##其他功能 1）认证&amp;权限 2）限流 控制用户访问API接口的频率。 针对匿名用户和认证用户分别进行限流。 1234567891011# 限流(针对匿名用户和认证用户分别进行限流控制)'DEFAULT_THROTTLE_CLASSES': ( 'rest_framework.throttling.AnonRateThrottle', # 针对匿名用户 'rest_framework.throttling.UserRateThrottle' # 针对认证用户),# 限流频次设置'DEFAULT_THROTTLE_RATES': &#123; 'user': '5/minute', # 认证用户5次每分钟 'anon': '3/minute', # 匿名用户3次每分钟&#125;, 针对匿名用户和认证用户统一进行限流。 123456789# 限流(针对匿名用户和认证用户进行统一限流控制)'DEFAULT_THROTTLE_CLASSES': ( 'rest_framework.throttling.ScopedRateThrottle',),'DEFAULT_THROTTLE_RATES': &#123; 'contacts': '5/minute', 'upload': '3/minute',&#125;, 3）过滤&amp;排序 4）分页 两种分页方式PageNumberPagination和LimitOffsetPagination。 使用PageNumberPagination分页时，获取分页数据时可以通过page传递页码参数。如果想要分页时指定页容量，需要自定义分页类。 1234567class StandardResultPagination(PageNumberPagination): # 默认页容量 page_size = 3 # 指定页容量参数名称 page_size_query_param = 'page_size' # 最大页容量 max_page_size = 5 使用LimitOffsetPagination分页时，获取分页数据时可以传递参数offset(偏移量)和limit(限制条数)。 注：如果使用的全局分页设置，某个列表视图如果不需要分页，直接在视图类中设置pagination_class = None。 5）异常 DRF自带异常处理功能，可以对某些特定的异常进行处理并返回给客户端组织好的错误信息。能够处理的异常如下: 12345678910APIException 所有异常的父类ParseError 解析错误AuthenticationFailed 认证失败NotAuthenticated 尚未认证PermissionDenied 权限决绝NotFound 未找到MethodNotAllowed 请求方式不支持NotAcceptable 要获取的数据格式不支持Throttled 超过限流次数ValidationError 校验失败 可以自定义DRF框架的异常处理函数(补充一些异常处理)并指定EXCEPTION_HANDLER配置项。 6）接口文档","categories":[{"name":"前后端分离","slug":"前后端分离","permalink":"https://zem12345678.github.io/categories/前后端分离/"}],"tags":[{"name":"Django","slug":"Django","permalink":"https://zem12345678.github.io/tags/Django/"},{"name":"Restful","slug":"Restful","permalink":"https://zem12345678.github.io/tags/Restful/"},{"name":"前后端分离","slug":"前后端分离","permalink":"https://zem12345678.github.io/tags/前后端分离/"}]},{"title":"SpringcloudVue项目学习笔记","slug":"SpringcloudVue项目学习笔记","date":"2018-11-14T12:21:21.836Z","updated":"2019-03-13T15:15:09.301Z","comments":true,"path":"2018/11/14/SpringcloudVue项目学习笔记/","link":"","permalink":"https://zem12345678.github.io/2018/11/14/SpringcloudVue项目学习笔记/","excerpt":"","text":"springcloud-vue-project架构图","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://zem12345678.github.io/categories/学习笔记/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://zem12345678.github.io/tags/SpringCloud/"},{"name":"Vue","slug":"Vue","permalink":"https://zem12345678.github.io/tags/Vue/"},{"name":"微服务","slug":"微服务","permalink":"https://zem12345678.github.io/tags/微服务/"},{"name":"Java","slug":"Java","permalink":"https://zem12345678.github.io/tags/Java/"}]},{"title":"day01-springboot","slug":"day01-springboot","date":"2018-11-14T12:13:33.696Z","updated":"2019-03-13T15:20:27.469Z","comments":true,"path":"2018/11/14/day01-springboot/","link":"","permalink":"https://zem12345678.github.io/2018/11/14/day01-springboot/","excerpt":"","text":"0.学习目标 了解SpringBoot的作用 掌握java配置的方式 了解SpringBoot自动配置原理 掌握SpringBoot的基本使用 了解Thymeleaf的基本使用 1. 了解SpringBoot在这一部分，我们主要了解以下3个问题： 什么是SpringBoot 为什么要学习SpringBoot SpringBoot的特点 1.1.什么是SpringBootSpringBoot是Spring项目中的一个子工程，与我们所熟知的Spring-framework 同属于spring的产品: 我们可以看到下面的一段介绍： Takes an opinionated view of building production-ready Spring applications. Spring Boot favors convention over configuration and is designed to get you up and running as quickly as possible. 翻译一下： 用一些固定的方式来构建生产级别的spring应用。Spring Boot 推崇约定大于配置的方式以便于你能够尽可能快速的启动并运行程序。 其实人们把Spring Boot 称为搭建程序的脚手架。其最主要作用就是帮我们快速的构建庞大的spring项目，并且尽可能的减少一切xml配置，做到开箱即用，迅速上手，让我们关注与业务而非配置。 1.2.为什么要学习SpringBootjava一直被人诟病的一点就是臃肿、麻烦。当我们还在辛苦的搭建项目时，可能Python程序员已经把功能写好了，究其原因注意是两点： 复杂的配置， 项目各种配置其实是开发时的损耗， 因为在思考 Spring 特性配置和解决业务问题之间需要进行思维切换，所以写配置挤占了写应用程序逻辑的时间。 一个是混乱的依赖管理。 项目的依赖管理也是件吃力不讨好的事情。决定项目里要用哪些库就已经够让人头痛的了，你还要知道这些库的哪个版本和其他库不会有冲突，这难题实在太棘手。并且，依赖管理也是一种损耗，添加依赖不是写应用程序代码。一旦选错了依赖的版本，随之而来的不兼容问题毫无疑问会是生产力杀手。 而SpringBoot让这一切成为过去！ Spring Boot 简化了基于Spring的应用开发，只需要“run”就能创建一个独立的、生产级别的Spring应用。Spring Boot为Spring平台及第三方库提供开箱即用的设置（提供默认设置，存放默认配置的包就是启动器），这样我们就可以简单的开始。多数Spring Boot应用只需要很少的Spring配置。 我们可以使用SpringBoot创建java应用，并使用java –jar 启动它，就能得到一个生产级别的web工程。 1.3.SpringBoot的特点Spring Boot 主要目标是： 为所有 Spring 的开发者提供一个非常快速的、广泛接受的入门体验 开箱即用（启动器starter-其实就是SpringBoot提供的一个jar包），但通过自己设置参数（.properties），即可快速摆脱这种方式。 提供了一些大型项目中常见的非功能性特性，如内嵌服务器、安全、指标，健康检测、外部化配置等 绝对没有代码生成，也无需 XML 配置。 更多细节，大家可以到官网查看。 2.快速入门接下来，我们就来利用SpringBoot搭建一个web工程，体会一下SpringBoot的魅力所在！ 2.1.创建工程我们先新建一个空的工程： 工程名为demo： 新建一个model： 使用maven来构建： 然后填写项目坐标： 目录结构： 项目结构： 2.2.添加依赖看到这里很多同学会有疑惑，前面说传统开发的问题之一就是依赖管理混乱，怎么这里我们还需要管理依赖呢？难道SpringBoot不帮我们管理吗？ 别着急，现在我们的项目与SpringBoot还没有什么关联。SpringBoot提供了一个名为spring-boot-starter-parent的工程，里面已经对各种常用依赖（并非全部）的版本进行了管理，我们的项目需要以这个项目为父工程，这样我们就不用操心依赖的版本问题了，需要什么依赖，直接引入坐标即可！ 2.2.1.添加父工程坐标12345&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.0.RELEASE&lt;/version&gt;&lt;/parent&gt; 2.2.2.添加web启动器为了让SpringBoot帮我们完成各种自动配置，我们必须引入SpringBoot提供的自动配置依赖，我们称为启动器。因为我们是web项目，这里我们引入web启动器： 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 需要注意的是，我们并没有在这里指定版本信息。因为SpringBoot的父工程已经对版本进行了管理了。 这个时候，我们会发现项目中多出了大量的依赖： 这些都是SpringBoot根据spring-boot-starter-web这个依赖自动引入的，而且所有的版本都已经管理好，不会出现冲突。 2.2.3.管理jdk版本默认情况下，maven工程的jdk版本是1.5，而我们开发使用的是1.8，因此这里我们需要修改jdk版本，只需要简单的添加以下属性即可： 123&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt;&lt;/properties&gt; 2.2.4.完整pom123456789101112131415161718192021222324252627&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.leyou.demo&lt;/groupId&gt; &lt;artifactId&gt;springboot-demo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.0.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2.3.启动类Spring Boot项目通过main函数即可启动，我们需要创建一个启动类： 然后编写main函数： 123456@SpringBootApplicationpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; 2.4.编写controller接下来，我们就可以像以前那样开发SpringMVC的项目了！ 我们编写一个controller： 代码： 12345678@RestControllerpublic class HelloController &#123; @GetMapping(\"hello\") public String hello()&#123; return \"hello, spring boot!\"; &#125;&#125; 2.5.启动测试接下来，我们运行main函数，查看控制台： 并且可以看到监听的端口信息： 1）监听的端口是8080 2）SpringMVC的映射路径是：/ 3）/hello路径已经映射到了HelloController中的hello()方法 打开页面访问：http://localhost:8080/hello 测试成功了！ 3.Java配置在入门案例中，我们没有任何的配置，就可以实现一个SpringMVC的项目了，快速、高效！ 但是有同学会有疑问，如果没有任何的xml，那么我们如果要配置一个Bean该怎么办？比如我们要配置一个数据库连接池，以前会这么玩： 1234567&lt;!-- 配置连接池 --&gt;&lt;bean id=\"dataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\" init-method=\"init\" destroy-method=\"close\"&gt; &lt;property name=\"url\" value=\"$&#123;jdbc.url&#125;\" /&gt; &lt;property name=\"username\" value=\"$&#123;jdbc.username&#125;\" /&gt; &lt;property name=\"password\" value=\"$&#123;jdbc.password&#125;\" /&gt;&lt;/bean&gt; 现在该怎么做呢？ 3.1.回顾历史事实上，在Spring3.0开始，Spring官方就已经开始推荐使用java配置来代替传统的xml配置了，我们不妨来回顾一下Spring的历史： Spring1.0时代 在此时因为jdk1.5刚刚出来，注解开发并未盛行，因此一切Spring配置都是xml格式，想象一下所有的bean都用xml配置，细思极恐啊，心疼那个时候的程序员2秒 Spring2.0时代 Spring引入了注解开发，但是因为并不完善，因此并未完全替代xml，此时的程序员往往是把xml与注解进行结合，貌似我们之前都是这种方式。 Spring3.0及以后 3.0以后Spring的注解已经非常完善了，因此Spring推荐大家使用完全的java配置来代替以前的xml，不过似乎在国内并未推广盛行。然后当SpringBoot来临，人们才慢慢认识到java配置的优雅。 有句古话说的好：拥抱变化，拥抱未来。所以我们也应该顺应时代潮流，做时尚的弄潮儿，一起来学习下java配置的玩法。 3.2.尝试java配置java配置主要靠java类和一些注解，比较常用的注解有： @Configuration：声明一个类作为配置类，代替xml文件 @Bean：声明在方法上，将方法的返回值加入Bean容器，代替&lt;bean&gt;标签 @value：属性注入 @PropertySource：指定外部属性文件， 我们接下来用java配置来尝试实现连接池配置： 首先引入Druid连接池依赖： 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.6&lt;/version&gt;&lt;/dependency&gt; 创建一个jdbc.properties文件，编写jdbc属性： 1234jdbc.driverClassName=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql://127.0.0.1:3306/leyoujdbc.username=rootjdbc.password=123 然后编写代码： 1234567891011121314151617181920212223@Configuration@PropertySource(\"classpath:jdbc.properties\")public class JdbcConfig &#123; @Value(\"$&#123;jdbc.url&#125;\") String url; @Value(\"$&#123;jdbc.driverClassName&#125;\") String driverClassName; @Value(\"$&#123;jdbc.username&#125;\") String username; @Value(\"$&#123;jdbc.password&#125;\") String password; @Bean public DataSource dataSource() &#123; DruidDataSource dataSource = new DruidDataSource(); dataSource.setUrl(url); dataSource.setDriverClassName(driverClassName); dataSource.setUsername(username); dataSource.setPassword(password); return dataSource; &#125;&#125; 解读： @Configuration：声明我们JdbcConfig是一个配置类 @PropertySource：指定属性文件的路径是:classpath:jdbc.properties 通过@Value为属性注入值 通过@Bean将 dataSource()方法声明为一个注册Bean的方法，Spring会自动调用该方法，将方法的返回值加入Spring容器中。 然后我们就可以在任意位置通过@Autowired注入DataSource了！ 我们在HelloController中测试： 1234567891011@RestControllerpublic class HelloController &#123; @Autowired private DataSource dataSource; @GetMapping(\"hello\") public String hello() &#123; return \"hello, spring boot!\" + dataSource; &#125;&#125; 然后Debug运行并查看： 属性注入成功了！ 3.3.SpringBoot的属性注入在上面的案例中，我们实验了java配置方式。不过属性注入使用的是@Value注解。这种方式虽然可行，但是不够强大，因为它只能注入基本类型值。 在SpringBoot中，提供了一种新的属性注入方式，支持各种java基本数据类型及复杂类型的注入。 1）我们新建一个类，用来进行属性注入： 123456789@ConfigurationProperties(prefix = \"jdbc\")public class JdbcProperties &#123; private String url; private String driverClassName; private String username; private String password; // ... 略 // getters 和 setters&#125; 在类上通过@ConfigurationProperties注解声明当前类为属性读取类 prefix=&quot;jdbc&quot;读取属性文件中，前缀为jdbc的值。 在类上定义各个属性，名称必须与属性文件中jdbc.后面部分一致 需要注意的是，这里我们并没有指定属性文件的地址，所以我们需要把jdbc.properties名称改为application.properties，这是SpringBoot默认读取的属性文件名： 2）在JdbcConfig中使用这个属性： 1234567891011121314@Configuration@EnableConfigurationProperties(JdbcProperties.class)public class JdbcConfig &#123; @Bean public DataSource dataSource(JdbcProperties jdbc) &#123; DruidDataSource dataSource = new DruidDataSource(); dataSource.setUrl(jdbc.getUrl()); dataSource.setDriverClassName(jdbc.getDriverClassName()); dataSource.setUsername(jdbc.getUsername()); dataSource.setPassword(jdbc.getPassword()); return dataSource; &#125;&#125; 通过@EnableConfigurationProperties(JdbcProperties.class)来声明要使用JdbcProperties这个类的对象 然后你可以通过以下方式注入JdbcProperties： @Autowired注入 12@Autowiredprivate JdbcProperties prop; 构造函数注入 1234private JdbcProperties prop;public JdbcConfig(Jdbcproperties prop)&#123; this.prop = prop;&#125; 声明有@Bean的方法参数注入 1234@Beanpublic Datasource dataSource(JdbcProperties prop)&#123; // ...&#125; 本例中，我们采用第三种方式。 3）测试结果： 大家会觉得这种方式似乎更麻烦了，事实上这种方式有更强大的功能，也是SpringBoot推荐的注入方式。两者对比关系： 优势： Relaxed binding：松散绑定 不严格要求属性文件中的属性名与成员变量名一致。支持驼峰，中划线，下划线等等转换，甚至支持对象引导。比如：user.friend.name：代表的是user对象中的friend属性中的name属性，显然friend也是对象。@value注解就难以完成这样的注入方式。 meta-data support：元数据支持，帮助IDE生成属性提示（写开源框架会用到）。 ​ 3.4.更优雅的注入事实上，如果一段属性只有一个Bean需要使用，我们无需将其注入到一个类（JdbcProperties）中。而是直接在需要的地方声明即可： 1234567891011@Configurationpublic class JdbcConfig &#123; @Bean // 声明要注入的属性前缀，SpringBoot会自动把相关属性通过set方法注入到DataSource中 @ConfigurationProperties(prefix = \"jdbc\") public DataSource dataSource() &#123; DruidDataSource dataSource = new DruidDataSource(); return dataSource; &#125;&#125; 我们直接把@ConfigurationProperties(prefix = &quot;jdbc&quot;)声明在需要使用的@Bean的方法上，然后SpringBoot就会自动调用这个Bean（此处是DataSource）的set方法，然后完成注入。使用的前提是：该类必须有对应属性的set方法！ 我们将jdbc的url改成：/heima，再次测试： 4.自动配置原理使用SpringBoot之后，一个整合了SpringMVC的WEB工程开发，变的无比简单，那些繁杂的配置都消失不见了，这是如何做到的？ 一切魔力的开始，都是从我们的main函数来的，所以我们再次来看下启动类： 我们发现特别的地方有两个： 注解：@SpringBootApplication run方法：SpringApplication.run() 我们分别来研究这两个部分。 4.1.了解@SpringBootApplication点击进入，查看源码： 这里重点的注解有3个： @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan 4.1.1.@SpringBootConfiguration我们继续点击查看源码： 通过这段我们可以看出，在这个注解上面，又有一个@Configuration注解。通过上面的注释阅读我们知道：这个注解的作用就是声明当前类是一个配置类，然后Spring会自动扫描到添加了@Configuration的类，并且读取其中的配置信息。而@SpringBootConfiguration是来声明当前类是SpringBoot应用的配置类，项目中只能有一个。所以一般我们无需自己添加。 4.1.2.@EnableAutoConfiguration关于这个注解，官网上有一段说明： The second class-level annotation is @EnableAutoConfiguration. This annotationtells Spring Boot to “guess” how you want to configure Spring, based on the jardependencies that you have added. Since spring-boot-starter-web added Tomcatand Spring MVC, the auto-configuration assumes that you are developing a webapplication and sets up Spring accordingly. 简单翻译以下： 第二级的注解@EnableAutoConfiguration，告诉SpringBoot基于你所添加的依赖，去“猜测”你想要如何配置Spring。比如我们引入了spring-boot-starter-web，而这个启动器中帮我们添加了tomcat、SpringMVC的依赖。此时自动配置就知道你是要开发一个web应用，所以就帮你完成了web及SpringMVC的默认配置了！ 总结，SpringBoot内部对大量的第三方库或Spring内部库进行了默认配置，这些配置是否生效，取决于我们是否引入了对应库所需的依赖，如果有那么默认配置就会生效。 所以，我们使用SpringBoot构建一个项目，只需要引入所需框架的依赖，配置就可以交给SpringBoot处理了。除非你不希望使用SpringBoot的默认配置，它也提供了自定义配置的入口。 4.1.3.@ComponentScan我们跟进源码： 并没有看到什么特殊的地方。我们查看注释： 大概的意思： 配置组件扫描的指令。提供了类似与&lt;context:component-scan&gt;标签的作用 通过basePackageClasses或者basePackages属性来指定要扫描的包。如果没有指定这些属性，那么将从声明这个注解的类所在的包开始，扫描包及子包 而我们的@SpringBootApplication注解声明的类就是main函数所在的启动类，因此扫描的包是该类所在包及其子包。因此，一般启动类会放在一个比较前的包目录中。 4.2.默认配置原理4.2.1默认配置类通过刚才的学习，我们知道@EnableAutoConfiguration会开启SpringBoot的自动配置，并且根据你引入的依赖来生效对应的默认配置。那么问题来了： 这些默认配置是在哪里定义的呢？ 为何依赖引入就会触发配置呢？ 其实在我们的项目中，已经引入了一个依赖：spring-boot-autoconfigure，其中定义了大量自动配置类： 还有： 非常多，几乎涵盖了现在主流的开源框架，例如： redis jms amqp jdbc jackson mongodb jpa solr elasticsearch … 等等 我们来看一个我们熟悉的，例如SpringMVC，查看mvc 的自动配置类： 打开WebMvcAutoConfiguration： 我们看到这个类上的4个注解： @Configuration：声明这个类是一个配置类 @ConditionalOnWebApplication(type = Type.SERVLET) ConditionalOn，翻译就是在某个条件下，此处就是满足项目的类是是Type.SERVLET类型，也就是一个普通web工程，显然我们就是 @ConditionalOnClass({ Servlet.class, DispatcherServlet.class, WebMvcConfigurer.class }) 这里的条件是OnClass，也就是满足以下类存在：Servlet、DispatcherServlet、WebMvcConfigurer，其中Servlet只要引入了tomcat依赖自然会有，后两个需要引入SpringMVC才会有。这里就是判断你是否引入了相关依赖，引入依赖后该条件成立，当前类的配置才会生效！ @ConditionalOnMissingBean(WebMvcConfigurationSupport.class) 这个条件与上面不同，OnMissingBean，是说环境中没有指定的Bean这个才生效。其实这就是自定义配置的入口，也就是说，如果我们自己配置了一个WebMVCConfigurationSupport的类，那么这个默认配置就会失效！ 接着，我们查看该类中定义了什么： 视图解析器： 处理器适配器（HandlerAdapter）： 还有很多，这里就不一一截图了。 4.2.2.默认配置属性另外，这些默认配置的属性来自哪里呢？ 我们看到，这里通过@EnableAutoConfiguration注解引入了两个属性：WebMvcProperties和ResourceProperties。这不正是SpringBoot的属性注入玩法嘛。 我们查看这两个属性类： 找到了内部资源视图解析器的prefix和suffix属性。 ResourceProperties中主要定义了静态资源（.js,.html,.css等)的路径： 如果我们要覆盖这些默认属性，只需要在application.properties中定义与其前缀prefix和字段名一致的属性即可。 4.3.总结SpringBoot为我们提供了默认配置，而默认配置生效的条件一般有两个： 你引入了相关依赖 你自己没有配置Bean 1）启动器 所以，我们如果不想配置，只需要引入依赖即可，而依赖版本我们也不用操心，因为只要引入了SpringBoot提供的stater（启动器），就会自动管理依赖及版本了。 因此，玩SpringBoot的第一件事情，就是找启动器，SpringBoot提供了大量的默认启动器，参考课前资料中提供的《SpringBoot启动器.txt》 2）全局配置 另外，SpringBoot的默认配置，都会读取默认属性，而这些属性可以通过自定义application.properties文件来进行覆盖。这样虽然使用的还是默认配置，但是配置中的值改成了我们自定义的。 因此，玩SpringBoot的第二件事情，就是通过application.properties来覆盖默认属性值，形成自定义配置。我们需要知道SpringBoot的默认属性key，非常多，参考课前资料提供的：《SpringBoot全局属性.md》 属性文件支持两种格式，application.properties和application.yml yml的语法实例： 12345678jdbc: driverClassName: com.mysql.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/leyou username: root password: 123server: port: 80 5.SpringBoot实践接下来，我们来看看如何用SpringBoot来玩转以前的SSM,我们沿用之前讲解SSM用到的数据库tb_user和实体类User 5.1.整合SpringMVC虽然默认配置已经可以使用SpringMVC了，不过我们有时候需要进行自定义配置。 5.1.1.修改端口查看SpringBoot的全局属性可知，端口通过以下方式配置： 12# 映射端口server.port=80 重启服务后测试： 5.1.2.访问静态资源现在，我们的项目是一个jar工程，那么就没有webapp，我们的静态资源该放哪里呢？ 回顾我们上面看的源码，有一个叫做ResourceProperties的类，里面就定义了静态资源的默认查找路径： 默认的静态资源路径为： classpath:/META-INF/resources/ classpath:/resources/ classpath:/static/ classpath:/public 只要静态资源放在这些目录中任何一个，SpringMVC都会帮我们处理。 我们习惯会把静态资源放在classpath:/static/目录下。我们创建目录，并且添加一些静态资源： 重启项目后测试 5.1.3.添加拦截器拦截器也是我们经常需要使用的，在SpringBoot中该如何配置呢？ 拦截器不是一个普通属性，而是一个类，所以就要用到java配置方式了。在SpringBoot官方文档中有这么一段说明： If you want to keep Spring Boot MVC features and you want to add additional MVC configuration (interceptors, formatters, view controllers, and other features), you can add your own @Configuration class of type WebMvcConfigurer but without @EnableWebMvc. If you wish to provide custom instances of RequestMappingHandlerMapping, RequestMappingHandlerAdapter, or ExceptionHandlerExceptionResolver, you can declare a WebMvcRegistrationsAdapter instance to provide such components. If you want to take complete control of Spring MVC, you can add your own @Configuration annotated with @EnableWebMvc. 翻译： 如果你想要保持Spring Boot 的一些默认MVC特征，同时又想自定义一些MVC配置（包括：拦截器，格式化器, 视图控制器、消息转换器 等等），你应该让一个类实现WebMvcConfigurer，并且添加@Configuration注解，但是千万不要加@EnableWebMvc注解。如果你想要自定义HandlerMapping、HandlerAdapter、ExceptionResolver等组件，你可以创建一个WebMvcRegistrationsAdapter实例 来提供以上组件。 如果你想要完全自定义SpringMVC，不保留SpringBoot提供的一切特征，你可以自己定义类并且添加@Configuration注解和@EnableWebMvc注解 总结：通过实现WebMvcConfigurer并添加@Configuration注解来实现自定义部分SpringMvc配置。 首先我们定义一个拦截器： 12345678910111213141516171819public class LoginInterceptor implements HandlerInterceptor &#123; private Logger logger = LoggerFactory.getLogger(LoginInterceptor.class); @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) &#123; logger.debug(\"preHandle method is now running!\"); return true; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) &#123; logger.debug(\"postHandle method is now running!\"); &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) &#123; logger.debug(\"afterCompletion method is now running!\"); &#125;&#125; 然后，我们定义配置类，注册拦截器： 123456789101112131415161718192021@Configurationpublic class MvcConfig implements WebMvcConfigurer&#123; /** * 通过@Bean注解，将我们定义的拦截器注册到Spring容器 * @return */ @Bean public LoginInterceptor loginInterceptor()&#123; return new LoginInterceptor(); &#125; /** * 重写接口中的addInterceptors方法，添加自定义拦截器 * @param registry */ @Override public void addInterceptors(InterceptorRegistry registry) &#123; // 通过registry来注册拦截器，通过addPathPatterns来添加拦截路径 registry.addInterceptor(this.loginInterceptor()).addPathPatterns(\"/**\"); &#125;&#125; 结构如下： 接下来运行并查看日志： 你会发现日志中什么都没有，因为我们记录的log级别是debug，默认是显示info以上，我们需要进行配置。 SpringBoot通过logging.level.*=debug来配置日志级别，*填写包名 12# 设置com.leyou包的日志级别为debuglogging.level.com.leyou=debug 再次运行查看： 1232018-05-05 17:50:01.811 DEBUG 4548 --- [p-nio-80-exec-1] com.leyou.interceptor.LoginInterceptor : preHandle method is now running!2018-05-05 17:50:01.854 DEBUG 4548 --- [p-nio-80-exec-1] com.leyou.interceptor.LoginInterceptor : postHandle method is now running!2018-05-05 17:50:01.854 DEBUG 4548 --- [p-nio-80-exec-1] com.leyou.interceptor.LoginInterceptor : afterCompletion method is now running! 5.2.整合jdbc和事务spring中的jdbc连接和事务是配置中的重要一环，在SpringBoot中该如何处理呢？ 答案是不需要处理，我们只要找到SpringBoot提供的启动器即可： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;&lt;/dependency&gt; 当然，不要忘了数据库驱动，SpringBoot并不知道我们用的什么数据库，这里我们选择MySQL： 1234&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;/dependency&gt; 至于事务，SpringBoot中通过注解来控制。就是我们熟知的@Transactional 123456789101112131415@Servicepublic class UserService &#123; @Autowired private UserMapper userMapper; public User queryById(Long id)&#123; return this.userMapper.selectByPrimaryKey(id); &#125; @Transactional public void deleteById(Long id)&#123; this.userMapper.deleteByPrimaryKey(id); &#125;&#125; 5.3.整合连接池其实，在刚才引入jdbc启动器的时候，SpringBoot已经自动帮我们引入了一个连接池：HikariCP应该是目前速度最快的连接池了，我们看看它与c3p0的对比： 因此，我们只需要指定连接池参数即可： 123456spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/heima30 username: root password: 123 当然，如果你更喜欢Druid连接池，也可以使用Druid官方提供的启动器： 123456&lt;!-- Druid连接池 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.6&lt;/version&gt;&lt;/dependency&gt; 而连接信息的配置与上面是类似的，只不过在连接池特有属性上，方式略有不同： 12345678910#初始化连接数spring.datasource.druid.initial-size=1#最小空闲连接spring.datasource.druid.min-idle=1#最大活动连接spring.datasource.druid.max-active=20#获取连接时测试是否可用spring.datasource.druid.test-on-borrow=true#监控页面启动spring.datasource.druid.stat-view-servlet.allow=true 5.4.整合mybatis5.4.1.mybatisSpringBoot官方并没有提供Mybatis的启动器，不过Mybatis官网自己实现了： 123456&lt;!--mybatis --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt;&lt;/dependency&gt; 配置，基本没有需要配置的： 1234# mybatis 别名扫描mybatis.type-aliases-package=com.heima.pojo# mapper.xml文件位置,如果没有映射文件，请注释掉mybatis.mapper-locations=classpath:mappers/*.xml 需要注意，这里没有配置mapper接口扫描包，因此我们需要给每一个Mapper接口添加@Mapper注解，才能被识别。 123@Mapperpublic interface UserMapper &#123;&#125; 或者，我们也可以不加注解，而是在启动类上添加扫描包注解： 12345678@SpringBootApplication@MapperScan(\"cn.itcast.demo.mapper\")public class Application &#123; public static void main(String[] args) &#123; // 启动代码 SpringApplication.run(Application.class, args); &#125;&#125; 5.4.2.通用mapper通用Mapper的作者也为自己的插件编写了启动器，我们直接引入即可： 123456&lt;!-- 通用mapper --&gt;&lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.2&lt;/version&gt;&lt;/dependency&gt; 不需要做任何配置就可以使用了。 123@Mapperpublic interface UserMapper extends tk.mybatis.mapper.common.Mapper&lt;User&gt;&#123;&#125; 5.5.启动测试将controller进行简单改造： 123456789101112@RestControllerpublic class HelloController &#123; @Autowired private UserService userService; @GetMapping(\"/hello\") public User hello() &#123; User user = this.userService.queryById(8L); return user; &#125;&#125; 我们启动项目，查看： 6.JDK1.8参考课前资料：JDK1.8新特性.md","categories":[{"name":"随堂笔记","slug":"随堂笔记","permalink":"https://zem12345678.github.io/categories/随堂笔记/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://zem12345678.github.io/tags/Java/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://zem12345678.github.io/tags/SpringBoot/"},{"name":"Spring","slug":"Spring","permalink":"https://zem12345678.github.io/tags/Spring/"}]},{"title":"RabbitMQ简介","slug":"RabbitMQ简介","date":"2018-10-19T03:29:16.775Z","updated":"2018-10-19T04:28:44.379Z","comments":true,"path":"2018/10/19/RabbitMQ简介/","link":"","permalink":"https://zem12345678.github.io/2018/10/19/RabbitMQ简介/","excerpt":"","text":"RabbitMQ是一个由erlang开发的AMQP（Advanced Message Queue ）的开源实现。AMQP 的出现其实也是应了广大人民群众的需求，虽然在同步消息通讯的世界里有很多公开标准（如 COBAR的 IIOP ，或者是 SOAP 等），但是在异步消息处理中却不是这样，只有大企业有一些商业实现（如微软的 MSMQ ，IBM 的 Websphere MQ 等），因此，在 2006 年的 6 月，Cisco 、Redhat、iMatix 等联合制定了 AMQP 的公开标准。 RabbitMQ是由RabbitMQ Technologies Ltd开发并且提供商业支持的。该公司在2010年4月被SpringSource（VMWare的一个部门）收购。在2013年5月被并入Pivotal。其实VMWare，Pivotal和EMC本质上是一家的。不同的是VMWare是独立上市子公司，而Pivotal是整合了EMC的某些资源，现在并没有上市。 RabbitMQ的官网是http://www.rabbitmq.comRabbitMQ 最初起源于金融系统，用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。具体特点包括： 什么叫消息队列(MQ)消息（Message）是指在应用间传送的数据。消息可以非常简单，比如只包含文本字符串，也可以更复杂，可能包含嵌入对象。 消息队列（Message Queue）是一种应用程序对应用程序的通信方法，消息发送后可以立即返回，由消息系统来确保消息的可靠传递。消息发布者只管把消息发布到 MQ 中而不用管谁来取，消息使用者只管从 MQ 中取消息而不管是谁发布的。这样发布者和使用者都不用知道对方的存在。通过消息队列通信，让A，B两个服务指间保持低耦合，实现业务的灵活拓展。 为何用消息队列(MQ)从上面的描述中可以看出消息队列是一种应用间的异步协作机制，那什么时候需要使用 MQ 呢？ 以常见的订单系统为例，用户点击【下单】按钮之后的业务逻辑可能包括：扣减库存、生成相应单据、发红包、发短信通知。在业务发展初期这些逻辑可能放在一起同步执行，随着业务的发展订单量增长，需要提升系统服务的性能，这时可以将一些不需要立即生效的操作拆分出来异步执行，比如发放红包、发短信通知等。这种场景下就可以用 MQ ，在下单的主流程（比如扣减库存、生成相应单据）完成之后发送一条消息到 MQ 让主流程快速完结，而由另外的单独线程拉取MQ的消息（或者由 MQ 推送消息），当发现 MQ 中有发红包或发短信之类的消息时，执行相应的业务逻辑。 以上是用于业务解耦的情况，其它常见场景包括最终一致性、广播、错峰流控等等。 RabbitMQ 特点 可靠性（Reliability）RabbitMQ 使用一些机制来保证可靠性，如持久化、传输确认、发布确认。 灵活的路由（Flexible Routing）在消息进入队列之前，通过 Exchange 来路由消息的。对于典型的路由功能，RabbitMQ 已经提供了一些内置的 Exchange 来实现。针对更复杂的路由功能，可以将多个 Exchange 绑定在一起，也通过插件机制实现自己的 Exchange 。 消息集群（Clustering）多个 RabbitMQ 服务器可以组成一个集群，形成一个逻辑 Broker 。 高可用（Highly Available Queues）队列可以在集群中的机器上进行镜像，使得在部分节点出问题的情况下队列仍然可用。 多种协议（Multi-protocol）RabbitMQ 支持多种消息队列协议，比如 STOMP、MQTT 等等。 多语言客户端（Many Clients）RabbitMQ 几乎支持所有常用语言，比如 Java、.NET、Ruby ,python,等等。 管理界面（Management UI）RabbitMQ 提供了一个易用的用户界面，使得用户可以监控和管理消息 Broker 的许多方面。 跟踪机制（Tracing）如果消息异常，RabbitMQ 提供了消息跟踪机制，使用者可以找出发生了什么。 插件机制（Plugin System）RabbitMQ 提供了许多插件，来从多方面进行扩展，也可以编写自己的插件。 RabbitMQ 中的概念模型消息模型所有 MQ 产品从模型抽象上来说都是一样的过程：消费者（consumer）订阅某个队列。生产者（producer）创建消息，然后发布到队列（queue）中，最后将消息发送到监听的消费者。 RabbitMQ 基本概念上面只是最简单抽象的描述，具体到 RabbitMQ 则有更详细的概念需要解释。上面介绍过 RabbitMQ 是 AMQP 协议的一个开源实现，所以其内部实际上也是 AMQP 中的基本概念： Message消息，消息是不具名的，它由消息头和消息体组成。消息体是不透明的，而消息头则由一系列的可选属性组成，这些属性包括routing-key（路由键）、priority（相对于其他消息的优先权）、delivery-mode（指出该消息可能需要持久性存储）等。 Publisher消息的生产者，也是一个向交换器发布消息的客户端应用程序。 Exchange交换器，用来接收生产者发送的消息并将这些消息路由给服务器中的队列。 Binding绑定，用于消息队列和交换器之间的关联。一个绑定就是基于路由键将交换器和消息队列连接起来的路由规则，所以可以将交换器理解成一个由绑定构成的路由表。 Queue消息队列，用来保存消息直到发送给消费者。它是消息的容器，也是消息的终点。一个消息可投入一个或多个队列。消息一直在队列里面，等待消费者连接到这个队列将其取走。 Connection网络连接，比如一个TCP连接。 Channel信道，多路复用连接中的一条独立的双向数据流通道。信道是建立在真实的TCP连接内地虚拟连接，AMQP 命令都是通过信道发出去的，不管是发布消息、订阅队列还是接收消息，这些动作都是通过信道完成。因为对于操作系统来说建立和销毁 TCP 都是非常昂贵的开销，所以引入了信道的概念，以复用一条 TCP 连接。 Consumer消息的消费者，表示一个从消息队列中取得消息的客户端应用程序。 Virtual Host虚拟主机，表示一批交换器、消息队列和相关对象。虚拟主机是共享相同的身份认证和加密环境的独立服务器域。每个 vhost 本质上就是一个 mini 版的 RabbitMQ 服务器，拥有自己的队列、交换器、绑定和权限机制。vhost 是 AMQP 概念的基础，必须在连接时指定，RabbitMQ 默认的 vhost 是 / 。 Broker表示消息队列服务器实体。AMQP 中的消息路由AMQP 中消息的路由过程和 Java 开发者熟悉的 JMS 存在一些差别，AMQP 中增加了 Exchange 和 Binding 的角色。生产者把消息发布到 Exchange 上，消息最终到达队列并被消费者接收，而 Binding 决定交换器的消息应该发送到那个队列。 Exchange 类型Exchange分发消息时根据类型的不同分发策略有区别，目前共四种类型：direct、fanout、topic、headers 。headers 匹配 AMQP 消息的 header 而不是路由键，此外 headers 交换器和 direct 交换器完全一致，但性能差很多，目前几乎用不到了，所以直接看另外三种类型： direct 消息中的路由键（routing key）如果和 Binding 中的 binding key 一致， 交换器就将消息发到对应的队列中。路由键与队列名完全匹配，如果一个队列绑定到交换机要求路由键为“dog”，则只转发 routing key 标记为“dog”的消息，不会转发“dog.puppy”，也不会转发“dog.guard”等等。它是完全匹配、单播的模式。 fanout 每个发到 fanout 类型交换器的消息都会分到所有绑定的队列上去。fanout 交换器不处理路由键，只是简单的将队列绑定到交换器上，每个发送到交换器的消息都会被转发到与该交换器绑定的所有队列上。很像子网广播，每台子网内的主机都获得了一份复制的消息。fanout 类型转发消息是最快的。 topic topic 交换器通过模式匹配分配消息的路由键属性，将路由键和某个模式进行匹配，此时队列需要绑定到一个模式上。它将路由键和绑定键的字符串切分成单词，这些单词之间用点隔开。它同样也会识别两个通配符：符号“#”和符号“”。#匹配0个或多个单词，匹配不多不少一个单词。","categories":[{"name":"异步处理","slug":"异步处理","permalink":"https://zem12345678.github.io/categories/异步处理/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"https://zem12345678.github.io/tags/消息队列/"},{"name":"分布式","slug":"分布式","permalink":"https://zem12345678.github.io/tags/分布式/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://zem12345678.github.io/tags/RabbitMQ/"}]},{"title":"Hadoop、Storm、Spark","slug":"Hadoop、Storm、Spark","date":"2018-10-18T07:28:29.350Z","updated":"2018-10-18T07:32:03.219Z","comments":true,"path":"2018/10/18/Hadoop、Storm、Spark/","link":"","permalink":"https://zem12345678.github.io/2018/10/18/Hadoop、Storm、Spark/","excerpt":"","text":"Storm与Spark、Hadoop这三种框架，各有各的优点，每个框架都有自己的最佳应用场景。所以，在不同的应用场景下，应该选择不同的框架。 StormStorm是最佳的流式计算框架，Storm由Java和Clojure写成，Storm的优点是全内存计算，所以它的定位是分布式实时计算系统，按照Storm作者的说法，Storm对于实时计算的意义类似于Hadoop对于批处理的意义。 Storm的适用场景：1）流数据处理Storm可以用来处理源源不断流进来的消息，处理之后将结果写入到某个存储中去。2）分布式RPC。由于Storm的处理组件是分布式的，而且处理延迟极低，所以可以作为一个通用的分布式RPC框架来使用。 sparkSparkSpark是一个基于内存计算的开源集群计算系统，目的是更快速的进行数据分析。Spark由加州伯克利大学AMP实验室Matei为主的小团队使用Scala开发开发，类似于Hadoop MapReduce的通用并行计算框架，Spark基于Map Reduce算法实现的分布式计算，拥有Hadoop MapReduce所具有的优点，但不同于MapReduce的是Job中间输出和结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的Map Reduce的算法。 Spark的适用场景：1）多次操作特定数据集的应用场合Spark是基于内存的迭代计算框架，适用于需要多次操作特定数据集的应用场合。需要反复操作的次数越多，所需读取的数据量越大，受益越大，数据量小但是计算密集度较大的场合，受益就相对较小。2）粗粒度更新状态的应用由于RDD的特性，Spark不适用那种异步细粒度更新状态的应用，例如Web服务的存储或者是增量的Web爬虫和索引。就是对于那种增量修改的应用模型不适合。总的来说Spark的适用面比较广泛且比较通用。 hadoopHadoop是实现了MapReduce的思想，将数据切片计算来处理大量的离线数据数据。Hadoop处理的数据必须是已经存放在HDFS上或者类似HBase的数据库中，所以Hadoop实现的时候是通过移动计算到这些存放数据的机器上来提高效率。 Hadoop的适用场景：1）海量数据的离线分析处理2）大规模Web信息搜索3）数据密集型并行计算 简单来说：Hadoop适合于离线的批量数据处理适用于对实时性要求极低的场景Storm适合于实时流数据处理，实时性方面做得极好Spark是内存分布式计算框架，试图吞并Hadoop的Map-Reduce批处理框架和Storm的流处理框架，但是Spark已经做得很不错了，批处理方面性能优于Map-Reduce，但是流处理目前还是弱于Storm，产品仍在改进之中","categories":[{"name":"大数据","slug":"大数据","permalink":"https://zem12345678.github.io/categories/大数据/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://zem12345678.github.io/tags/大数据/"},{"name":"Hadoop","slug":"Hadoop","permalink":"https://zem12345678.github.io/tags/Hadoop/"}]},{"title":"python基础小谈","slug":"python基础小谈","date":"2018-10-18T06:55:13.351Z","updated":"2018-10-18T07:07:25.385Z","comments":true,"path":"2018/10/18/python基础小谈/","link":"","permalink":"https://zem12345678.github.io/2018/10/18/python基础小谈/","excerpt":"","text":"python语音是动态解释类型的，被称为胶水语言，再python的底层函数我们会经常看到两个形参*args,**kwargs，那么它们的本质是什么，什么使用它们呢？ 一 .*args 和 **kwargs 是什么？*args本质是一个tuple（元组），**kwargs本质是一个dict（字典）。 二.怎么用 *args 和 **kwargs?def my_fun(*args, **kwargs ): print (‘args = ‘, args) print (‘kwargs = ‘, kwargs) 调用就比较有意思了，传统的比如，c, c++, Java, C#，基本都是一对一传参，但是python靠这两个参数，可以实现多参的灵活传入。如下所示，我完全可以这么调用： my_fun(1,3,5,9, a=2, b=4) 这样打印的结果： args = (1,3,5,9) # 是一个元组 kwargs = { ‘a’: 2 , ‘b’:4 } #是一个字典 注意事项：上述函数 my_fun，如果这么调用就会有问题： my_fun( a=2, b=4, 1,3,5,9 ) 报错：SyntaxError: non-keyword arg after keyword arg” 意思是：关键字参数后面不能有非关键字参数，言外之意，关键字参数 * kwargs 必须位于 args 之后！","categories":[{"name":"Python","slug":"Python","permalink":"https://zem12345678.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://zem12345678.github.io/tags/Python/"}]},{"title":"Thinking In Python Language","slug":"Thinking In Python Language","date":"2018-10-18T05:54:54.070Z","updated":"2018-11-14T03:10:47.353Z","comments":true,"path":"2018/10/18/Thinking In Python Language/","link":"","permalink":"https://zem12345678.github.io/2018/10/18/Thinking In Python Language/","excerpt":"","text":"1.前言本文诞生于利用 Topic Reading 方法读 Python 若干本技术书籍这个过程中结合自己的开发常见场景记录下来的一些笔记。 2.简介1. 为什么是 Python Python, 很大程度上是因为 Python 的快速开发。 当然，快速开发（这里的开发包含部署）这个词也往往会被误解。什么叫做快速？我用一个 CMS 框架快速搭建出一个网站这是否叫做快速？ 每一次部署的时候，如果使用 Java 或者是 Go, 部署的时候直接 maven 编译打包，接着把 War 包直接上传到 Tomcat 就结束了。而用 Python 则需要各种虚拟环境，各种稀里哗啦的配置。这种情况下是哪一种快速呢？Python 有什么好处呢？ 写代码效率高。 生态圈好。 写代码效率高，这指的是写 Python 代码，而不是运行时。3.写代码效率高，这指的是写 Python 代码，而不是运行时。 生态圈好，Web 开发用 Django/Flask , 数据抓取用 Requests , 数据分析清洗用 Pandas, 机器学习。 2. 工具链 Anaconda工具：https://www.anaconda.com/download/ 3. 文档 官方文档：https://docs.python.org/3/ 4. 社区 官方社区：https://www.python.org/community/ 4. 书籍 《python核心编程》，《python编程从入门到实践》 3. 基本概念 程序 = 算法 + 数据结构 这句话当然是不全面的，但并不影响这句话在计算机世界里面的地位。依我看来，对我的启发大致是：我会把 API 的调用和数据结构以及算法想清楚，然后才动手把代码分解成伪代码。 1.数据类型数据类型按照不同的划分标准可以进行不同的划分： 按照复杂性可以这么划分： 简单类型 复杂类型】 按照复杂性可以这么划分： 基本类型 引用类型 按照数据结构可以这么划分： 集合结构 : 串 线性结构 : 线性表 （单链表，静态链表，循环链表，双向链表，栈，队列) 树形结构 : 树（二叉树，B+ 树，红黑树） 图形结构 : 图 2. 操作对于一些基本的数据类型，操作为 加减乘除取余数位运算等等 对于复杂的一些数据类型，则需要对数据结构多一些了解。 比如，对队列而言，增删改查在算法复杂度上意味着什么？对机器的性能会不会有很多影响呢？比如，对 hash 而言，增删改查在算法复杂度上意味着什么？对机器的性能会不会有很多影响呢？比如，对字典而言，增删改查在算法复杂度上意味着什么？对机器的性能会不会有很多影响呢？比如，对字符串而言，增删改查在算法复杂度上意味着什么？对机器的性能会不会有很多影响呢？ 那字符串来说，Java 推荐使用 StringBuilder 来合并多个字符串，Python 推荐 join 多个字符串等等。 4.1.函数2.作用域3.模块模块，这个概念，可大可小，大的时候，把一个程序说成是模块，小的时候，可以把一个文件，甚至你说这一个函数是一个模块，也行。 这里的模块指的是一个包下的函数。 4.面向对象面向对象有三大概念： 封装 继承 多态5.错误 / 调试测试异常处理实际上可以考验一个程序员编写代码的健壮性。 事实上来说，代码写的健壮是一个程序员必备的素养。但其实在开发过程中，出于对项目进行赶工上线，需要对程序的健壮性做出一定的取舍。并且，在编写客户端，服务端，网页前端的时候基本上都会遇到这个问题。什么时候选择健壮的程序，什么时候选择是还可以的程序。需要自己的经验。 6. IO 编程7.进程和线程1.多线程 Python 多线程约等于并发。 2.多进程3.GILGlobal Interpreter Lock 并不是所有的解释器语言都有 GIL （尽管 Python 和 Ruby 里面都有）, 也并不是没有尝试过去除 GIL, 但是每次去除都会导致单线程性能的下降。所以暂时保留。 GIL 对程序中的影响： 一个线程运行 Python , 而其他 N 个睡眠或者等待 I/O - 同一时刻只有一个线程对共享资源进行存取 , Python 线程也可以等待 threading.Lock 或者线程模块中的其他同步对象； 协同式多任务处理如果有两个线程，同时进行 IO 请求，当其中一个线程连接之后，立即会主动让出 GIL, 其他线程就可以运行。 当N 个线程在网络 I/O 堵塞，或等待重新获取 GIL，而一个线程运行 Python。 让出之后还要执行代码呀，所以要有个收回 GIL 的动作。 抢占式多任务处理Python 2 GIL , 尝试收回 GIL 为 执行 1000 字节码。Python 3 GIL , 尝试收回 GIL 检测间隔为 15ms 线程安全原子操作：sort 之类不需要非原子操作：n=n+2 的字节码分为 加载 n , 加载 2 , 相加，存储 n, 四个步骤，由于不是原子性，很可能被由于 15 ms 而被打断。 当然，懒人一向是 : 优先级不决加括号，线程不决加 lock 对于 Java, 程序员努力在尽可能短的时间内加锁存取共享数据，减轻线程的争夺，实现最大并行。但 Python 中，线程无法并行运行，细粒度的锁就没有了优势。 8.正则表达式5.高级技巧6.标准库常用内建模块系统化模块IntroductionBuilt-in FunctionsBuilt-in ConstantsBuilt-in TypesBuilt-in ExceptionsText Processing ServicesBinary Data ServicesData TypesNumeric and Mathematical ModulesFunctional Programming ModulesFile and Directory AccessData PersistenceData Compression and ArchivingFile FormatsCryptographic ServicesGeneric Operating System ServicesConcurrent ExecutionInterprocess Communication and NetworkingInternet Data HandlingStructured Markup Processing ToolsInternet Protocols and SupportMultimedia ServicesInternationalizationProgram FrameworksGraphical User Interfaces with TkDevelopment ToolsDebugging and ProfilingSoftware Packaging and DistributionPython Runtime ServicesCustom Python InterpretersImporting ModulesPython Language ServicesMiscellaneous ServicesMS Windows Specific ServicesUnix Specific ServicesSuperseded ModulesUndocumented Modules 7.第三方库Requests : API 人性化 8.代码质量1.正确性 外部不该引用 protected member （单下划线）lambda 为一次使用，最好不要赋值。不要给 buildin 函数赋值py3 直接 super()for in else 如果不内置 break 则出会在最后 for in 为 empty 的时候再执行 else 中的语句context exit 如果不 catch 掉异常让其自然向上一级抛出错误的话，必须为 (self, exception_type, exception_value, traceback):不要在 init 里面 return 数据不要混用 tab 和 space4 个 space 缩进staticmethod 直接是 参数，classmethod 第一个参数为 cls可变的 default value 是不能作为 参数的。（可能是解释器在确定函数的定义的时候完成赋值？)遵循 exception hierachy https://docs.python.org/3/library/exceptions.html#exception-hierarchydefaultdict defaultdict(lambda : 6) , 必须 callable尽量 unpack 赋值字典用获取用 get(“myk”,None) , 赋值用 dictionary.setdefault(“list”, []).append(“list_item”) 2.可维护性 避免使用 import * , 我觉得这点值得商榷 , 如果是某个模块下，完全可以先把模块拆分成多个，最后 import 进来，接着使用 all.getxxx 获取实际值，如果不为实际值，返回 None 显然不如 try catch 来的实在。避免使用 global命名要注意动态创建方法 , 我觉得这点值得商榷。 3.可读性 不要检查，如果可能有异常，尽量抛出异常来 trycatch 解决。a is None , if flagisinstance , not type(r) is types.ListType“{name}{city}”.format(**info_dict)for k , v in infodict.items()使用 poiinfo = namedtuple(“poiinfo”,[“name”,”lng”,”lat”]) 返回 poiinfo[‘上海’,121.00,23] 最后返回值打印 poi.name , poi.lng , poi latfor numbers_value, letters_value in zip(numbers, letters):enumerate如果能用 listcomp 则不使用 map 和 filter 4.安全性5.性能","categories":[{"name":"Python","slug":"Python","permalink":"https://zem12345678.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://zem12345678.github.io/tags/Python/"},{"name":"杂谈","slug":"杂谈","permalink":"https://zem12345678.github.io/tags/杂谈/"}]},{"title":"Jquery ajax, Axios, Fetch区别浅谈","slug":"Jquery ajax, Axios, Fetch区别浅谈","date":"2018-10-16T10:57:03.472Z","updated":"2018-10-16T12:26:10.813Z","comments":true,"path":"2018/10/16/Jquery ajax, Axios, Fetch区别浅谈/","link":"","permalink":"https://zem12345678.github.io/2018/10/16/Jquery ajax, Axios, Fetch区别浅谈/","excerpt":"","text":"前端技术是一个发展飞快的领域,JQuery ajax早已不能专美于前，axios和fetch都已经开始分别抢占“请求”这个前端高地。 1 JQuery ajax：廉颇老矣。尚能饭，但总有饭不动的一天。1234567891011$.ajax(&#123; type: &apos;POST&apos;, url: url, data: data, dataType: dataType, success: function () &#123;&#125;, error: function () &#123;&#125;&#125;); 这个我就不用多言了把，是对原生XHR的封装，除此以外还增添了对JSONP的支持。有一说一的说一句，JQuery ajax经过多年的更新维护，真的已经是非常的方便了，优点无需多言；如果是硬要举出几个缺点，那可能只有: 本身是针对MVC的编程,不符合现在前端MVVM的浪潮 基于原生的XHR开发，XHR本身的架构不清晰，已经有了fetch的替代方案 JQuery整个项目太大，单纯使用ajax却要引入整个JQuery非常的不合理（采取个性化打包的方案又不能享受CDN服务） 尽管JQuery对我们前端的开发工作曾有着（现在也仍然有着）深远的影响，但是我们可以看到随着VUE，REACT新一代框架的兴起，以及ES规范的完善，更多API的更新，JQuery这种大而全的JS库，未来的路会越走越窄。 2 Axios： 谁敢横刀立马，唯我Axios大将军！1234567891011121314axios(&#123; method: &apos;post&apos;, url: &apos;/user/12345&apos;, data: &#123; firstName: &apos;Fred&apos;, lastName: &apos;Flintstone&apos; &#125;&#125;).then(function (response) &#123; console.log(response);&#125;).catch(function (error) &#123; console.log(error);&#125;); Vue2.0之后，尤雨溪推荐大家用axios替换JQuery ajax，想必让Axios进入了很多人的目光中。Axios本质上也是对原生XHR的封装，只不过它是Promise的实现版本，符合最新的ES规范，从它的官网上可以看到它有以下几条特性： 从 node.js 创建 http 请求 支持 Promise API ； 客户端支持防止CSRF 提供了一些并发请求的接口（重要，方便了很多的操作） 这个支持防止CSRF其实挺好玩的，是怎么做到的呢，就是让你的每个请求都带一个从cookie中拿到的key, 根据浏览器同源策略，假冒的网站是拿不到你cookie中得key的，这样，后台就可以轻松辨别出这个请求是否是用户在假冒网站上的误导输入，从而采取正确的策略。Axios既提供了并发的封装，也没有下文会提到的fetch的各种问题，而且体积也较小，当之无愧现在最应该选用的请求的方式。 3 Fetch ：酋长的孩子,还需成长fetch号称是AJAX的替代品，它的好处在《传统 Ajax 已死，Fetch 永生》中提到有以下几点： 符合关注分离，没有将输入、输出和用事件来跟踪的状态混杂在一个对象里 更好更方便的写法，诸如： 1234try &#123; let response = await fetch(url); let data = response.json(); console.log(data);&#125; catch(e) &#123; console.log(&quot;Oops, error&quot;, e);&#125; 坦白说，上面的理由对我来说完全没有什么说服力，因为不管是Jquery还是Axios都已经帮我们把xhr封装的足够好，使用起来也足够方便，为什么我们还要花费大力气去学习fetch？我认为fetch的优势主要优势就是： 更加底层，提供的API丰富（request, response） 脱离了XHR，是ES规范里新的实现方式 偶尔觉得写的丑陋，但是在使用了JQuery和axios之后，已经对这一块完全无所谓了。当然，如果新的fetch能做的同样好，我为了不掉队也会选择使用fetch。这个道理其实很好理解：你有一架歼8，魔改了N次，性能达到了歼10的水准，但是要是有个人给你拿来一架新的歼10，你也会毫不犹豫的选择新的歼10——不仅仅是新，也代表了还有新的魔改潜力。但是我最近在使用fetch的时候，也遇到了不少的问题 fetch是一个低层次的API，你可以把它考虑成原生的XHR，所以使用起来并不是那么舒服，需要进行封装 例如： 1）fetch只对网络请求报错，对400，500都当做成功的请求，需要封装去处理2）fetch默认不会带cookie，需要添加配置项3）fetch不支持abort，不支持超时控制，使用setTimeout及Promise.reject的实现的超时控制并不能阻止请求过程继续在后台运行，造成了流量的浪费4）fetch没有办法原生监测请求的进度，而XHR可以 PS: fetch的具体问题大家可以参考：《fetch没有你想象的那么美》《fetch使用的常见问题及解决方法》 看到这里，你心里一定有个疑问，这鬼东西就是个半拉子工程嘛，我还是回去用Jquery或者Axios算了——其实我就是这么打算的。但是，必须要提出的是，我发现fetch在前端的应用上有一项xhr怎么也比不上的能力：跨域的处理。 我们都知道因为同源策略的问题，浏览器的请求是可能随便跨域的——一定要有跨域头或者借助JSONP，但是，fetch中可以设置mode为”no-cors”（不跨域），如下所示： 123fetch(&apos;/users.json&apos;, &#123; method: &apos;post&apos;, mode: &apos;no-cors&apos;, data: &#123;&#125;&#125;).then(function() &#123; /* handle response */ &#125;); 这样之后我们会得到一个type为“opaque”的返回。需要指出的是，这个请求是真正抵达过后台的，所以我们可以使用这种方法来进行信息上报，在我们之前的image.src方法中多出了一种选择，另外，我们在network中可以看到这个请求后台设置跨域头之后的实际返回，有助于我们提前调试接口（当然，通过chrome插件我们也可以做的到）。总之，fetch现在还不是很好用，我尝试过几个fetch封装的包，都还不尽如人意。 总结现在只需要知道无脑使用axios即可，Jquery老迈笨拙，fetch年轻稚嫩，只有Axios正当其年！","categories":[{"name":"前端","slug":"前端","permalink":"https://zem12345678.github.io/categories/前端/"}],"tags":[{"name":"前端","slug":"前端","permalink":"https://zem12345678.github.io/tags/前端/"},{"name":"跨域","slug":"跨域","permalink":"https://zem12345678.github.io/tags/跨域/"}]},{"title":"Hello World","slug":"hello-world","date":"2018-10-16T03:24:15.311Z","updated":"2018-10-16T03:24:15.311Z","comments":true,"path":"2018/10/16/hello-world/","link":"","permalink":"https://zem12345678.github.io/2018/10/16/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}